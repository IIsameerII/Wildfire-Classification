{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SameerAhamed\\anaconda3\\envs\\not_base_v3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import Nessecary Libraries\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "from going_modular import data_setup, engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\\ntry:\\n    import torch\\n    import torchvision\\n    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\\n    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\\n    print(f\"torch version: {torch.__version__}\")\\n    print(f\"torchvision version: {torchvision.__version__}\")\\nexcept:\\n    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\\n    !pip3 install -U --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cu113\\n    import torch\\n    import torchvision\\n    print(f\"torch version: {torch.__version__}\")\\n    print(f\"torchvision version: {torchvision.__version__}\")\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
    "    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")\n",
    "except:\n",
    "    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
    "    !pip3 install -U --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cu113\n",
    "    import torch\n",
    "    import torchvision\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# Batch_size of dataset\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "def set_seeds(seed: int=42):\n",
    "    \"\"\"Sets random sets for torch operations.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): Random seed to set. Defaults to 42.\n",
    "    \"\"\"\n",
    "    # Set the seed for general torch operations\n",
    "    torch.manual_seed(seed)\n",
    "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/SameerAhamed/Downloads/Wildfire Prediction Dataset (Satellite Images)')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "image_path = Path(r'C:\\Users\\SameerAhamed\\Downloads\\Wildfire Prediction Dataset (Satellite Images)')\n",
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('C:/Users/SameerAhamed/Downloads/Wildfire Prediction Dataset (Satellite Images)/train'),\n",
       " WindowsPath('C:/Users/SameerAhamed/Downloads/Wildfire Prediction Dataset (Satellite Images)/test'),\n",
       " WindowsPath('C:/Users/SameerAhamed/Downloads/Wildfire Prediction Dataset (Satellite Images)/valid'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup directories\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path /\"test\"\n",
    "valid_dir = image_path /'valid'\n",
    "\n",
    "train_dir, test_dir, valid_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created transforms: ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[256]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BICUBIC\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # \"DEFAULT\" = best available\n",
    "\n",
    "# Get transforms from weights (these are the transforms used to train a particular or obtain a particular set of weights)\n",
    "automatic_transforms = weights.transforms()\n",
    "print(f\"Automatically created transforms: {automatic_transforms}\")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
    "                                                                               test_dir=test_dir,\n",
    "                                                                               transform=automatic_transforms,\n",
    "                                                                               batch_size=batch_size)\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the pretrained weights for EfficientNet_B0\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT # \"DEFAULT\" = best available weights\n",
    "\n",
    "# Setup the model with the pretrained weights and send it to the target device\n",
    "model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the classifier head\n",
    "from torch import nn\n",
    "\n",
    "set_seeds()\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, out_features=len(class_names))).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [32, 3, 224, 224]    [32, 2]              --                   True\n",
       "├─Sequential (features)                                      [32, 3, 224, 224]    [32, 1280, 7, 7]     --                   True\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]    [32, 32, 112, 112]   --                   True\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 224, 224]    [32, 32, 112, 112]   864                  True\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112]   [32, 32, 112, 112]   64                   True\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n",
       "│    └─Sequential (1)                                        [32, 32, 112, 112]   [32, 16, 112, 112]   --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 32, 112, 112]   [32, 16, 112, 112]   1,448                True\n",
       "│    └─Sequential (2)                                        [32, 16, 112, 112]   [32, 24, 56, 56]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112]   [32, 24, 56, 56]     6,004                True\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56]     [32, 24, 56, 56]     10,710               True\n",
       "│    └─Sequential (3)                                        [32, 24, 56, 56]     [32, 40, 28, 28]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56]     [32, 40, 28, 28]     15,350               True\n",
       "│    │    └─MBConv (1)                                       [32, 40, 28, 28]     [32, 40, 28, 28]     31,290               True\n",
       "│    └─Sequential (4)                                        [32, 40, 28, 28]     [32, 80, 14, 14]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 40, 28, 28]     [32, 80, 14, 14]     37,130               True\n",
       "│    │    └─MBConv (1)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     102,900              True\n",
       "│    │    └─MBConv (2)                                       [32, 80, 14, 14]     [32, 80, 14, 14]     102,900              True\n",
       "│    └─Sequential (5)                                        [32, 80, 14, 14]     [32, 112, 14, 14]    --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 80, 14, 14]     [32, 112, 14, 14]    126,004              True\n",
       "│    │    └─MBConv (1)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    208,572              True\n",
       "│    │    └─MBConv (2)                                       [32, 112, 14, 14]    [32, 112, 14, 14]    208,572              True\n",
       "│    └─Sequential (6)                                        [32, 112, 14, 14]    [32, 192, 7, 7]      --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 112, 14, 14]    [32, 192, 7, 7]      262,492              True\n",
       "│    │    └─MBConv (1)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      587,952              True\n",
       "│    │    └─MBConv (2)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      587,952              True\n",
       "│    │    └─MBConv (3)                                       [32, 192, 7, 7]      [32, 192, 7, 7]      587,952              True\n",
       "│    └─Sequential (7)                                        [32, 192, 7, 7]      [32, 320, 7, 7]      --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 192, 7, 7]      [32, 320, 7, 7]      717,232              True\n",
       "│    └─Conv2dNormActivation (8)                              [32, 320, 7, 7]      [32, 1280, 7, 7]     --                   True\n",
       "│    │    └─Conv2d (0)                                       [32, 320, 7, 7]      [32, 1280, 7, 7]     409,600              True\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7]     [32, 1280, 7, 7]     2,560                True\n",
       "│    │    └─SiLU (2)                                         [32, 1280, 7, 7]     [32, 1280, 7, 7]     --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7]     [32, 1280, 1, 1]     --                   --\n",
       "├─Sequential (classifier)                                    [32, 1280]           [32, 2]              --                   True\n",
       "│    └─Dropout (0)                                           [32, 1280]           [32, 1280]           --                   --\n",
       "│    └─Linear (1)                                            [32, 1280]           [32, 2]              2,562                True\n",
       "============================================================================================================================================\n",
       "Total params: 4,010,110\n",
       "Trainable params: 4,010,110\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 12.31\n",
       "============================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3452.09\n",
       "Params size (MB): 16.04\n",
       "Estimated Total Size (MB): 3487.40\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model,\n",
    "        input_size=(32, 3, 224, 224),\n",
    "        verbose=0,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training starts from here. \n",
    "\n",
    "## NOTE: Kept code below to cause an error to stop training loop from running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorboardX.writer.SummaryWriter at 0x23c86232440>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define loss function optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (304270658.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[24], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    ..\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    ".."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a SummaryWriter\n",
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from going_modular.engine import train_step, test_step\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device) -> Dict[str, List]:\n",
    "    \"\"\"Trains and tests a PyTorch model.\n",
    "\n",
    "    Passes a target PyTorch models through train_step() and test_step()\n",
    "    functions for a number of epochs, training and testing the model\n",
    "    in the same epoch loop.\n",
    "\n",
    "    Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "    Args:\n",
    "    model: A PyTorch model to be trained and tested.\n",
    "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
    "    epochs: An integer indicating how many epochs to train for.\n",
    "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
    "\n",
    "    Returns:\n",
    "    A dictionary of training and testing loss as well as training and\n",
    "    testing accuracy metrics. Each metric has a value in a list for \n",
    "    each epoch.\n",
    "    In the form: {train_loss: [...],\n",
    "              train_acc: [...],\n",
    "              test_loss: [...],\n",
    "              test_acc: [...]} \n",
    "    For example if training for epochs=2: \n",
    "             {train_loss: [2.0616, 1.0537],\n",
    "              train_acc: [0.3945, 0.3945],\n",
    "              test_loss: [1.2641, 1.5706],\n",
    "              test_acc: [0.3400, 0.2973]} \n",
    "    \"\"\"\n",
    "    # Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"test_loss\": [],\n",
    "               \"test_acc\": []\n",
    "    }\n",
    "\n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                          dataloader=train_dataloader,\n",
    "                                          loss_fn=loss_fn,\n",
    "                                          optimizer=optimizer,\n",
    "                                          device=device)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "          dataloader=test_dataloader,\n",
    "          loss_fn=loss_fn,\n",
    "          device=device)\n",
    "\n",
    "        # Print out what's happening\n",
    "        print(\n",
    "          f\"Epoch: {epoch+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "        ### New: Experiment tracking ###\n",
    "        # See SummaryWriter documentation\n",
    "        writer.add_scalars(main_tag=\"Loss\",\n",
    "                           tag_scalar_dict={\"train_loss\": train_loss,\n",
    "                                            \"test_loss\": test_loss},\n",
    "                           global_step=epoch)\n",
    "        \n",
    "        writer.add_scalars(main_tag=\"Accuracy\",\n",
    "                           tag_scalar_dict={\"train_acc\": train_acc,\n",
    "                                            \"test_acc\": test_acc},\n",
    "                           global_step=epoch)\n",
    "        \n",
    "        writer.add_graph(model=model,\n",
    "                         input_to_model=torch.randn(32, 3, 224, 224).to(device))\n",
    "\n",
    "    # Close the writer\n",
    "    writer.close()\n",
    "    ### End new ### \n",
    "\n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.0939 | train_acc: 0.9671 | test_loss: 0.0346 | test_acc: 0.9895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [04:22<04:22, 262.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.0481 | train_acc: 0.9829 | test_loss: 0.0313 | test_acc: 0.9886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [08:45<00:00, 262.63s/it]\n"
     ]
    }
   ],
   "source": [
    "set_seeds()\n",
    "results = train(model=model,\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                optimizer=optimizer,\n",
    "                loss_fn=loss_fn,\n",
    "                epochs=2,\n",
    "                device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model to: model\\EfficientNet_b0-Wildfire_Classifier.pt\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "\n",
    "from going_modular.utils import save_model\n",
    "\n",
    "save_model(model=model,\n",
    "           target_dir=r\"model\",\n",
    "           model_name=r\"EfficientNet_b0-Wildfire_Classifier.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\SameerAhamed\\Documents\\GitHub\\Wildfire-Classification\\wildfire-classification.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SameerAhamed/Documents/GitHub/Wildfire-Classification/wildfire-classification.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model_loaded \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mefficientnet_b0()\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SameerAhamed/Documents/GitHub/Wildfire-Classification/wildfire-classification.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model_loaded\u001b[39m.\u001b[39mclassifier \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/SameerAhamed/Documents/GitHub/Wildfire-Classification/wildfire-classification.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     nn\u001b[39m.\u001b[39mDropout(p\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/SameerAhamed/Documents/GitHub/Wildfire-Classification/wildfire-classification.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     nn\u001b[39m.\u001b[39mLinear(in_features\u001b[39m=\u001b[39m\u001b[39m1280\u001b[39m, out_features\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))\u001b[39m.\u001b[39mto(device) \u001b[39m# Hardcoded the class names\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/SameerAhamed/Documents/GitHub/Wildfire-Classification/wildfire-classification.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m model_loaded \u001b[39m=\u001b[39m load_model(model_loaded, Path(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mEfficientNet_b0-Wildfire_Classifier.pt\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\SameerAhamed\\Documents\\GitHub\\Wildfire-Classification\\going_modular\\utils.py:50\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(model, weights_path)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model\u001b[39m(model, weights_path):\n\u001b[0;32m     38\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Loads a PyTorch model from a target directory.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39m               )\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(weights_path))\n\u001b[0;32m     51\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\SameerAhamed\\anaconda3\\envs\\not_base_v2\\Lib\\site-packages\\torch\\serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    808\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 809\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m    810\u001b[0m \u001b[39mif\u001b[39;00m weights_only:\n\u001b[0;32m    811\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\SameerAhamed\\anaconda3\\envs\\not_base_v2\\Lib\\site-packages\\torch\\serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1170\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1171\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[1;32m-> 1172\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39mload()\n\u001b[0;32m   1174\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   1176\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\SameerAhamed\\anaconda3\\envs\\not_base_v2\\Lib\\site-packages\\torch\\serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1141\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1142\u001b[0m     typed_storage \u001b[39m=\u001b[39m load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[0;32m   1144\u001b[0m \u001b[39mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\SameerAhamed\\anaconda3\\envs\\not_base_v2\\Lib\\site-packages\\torch\\serialization.py:1116\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1112\u001b[0m storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39mUntypedStorage)\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_untyped_storage\n\u001b[0;32m   1113\u001b[0m \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m   1114\u001b[0m \u001b[39m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m typed_storage \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39mTypedStorage(\n\u001b[1;32m-> 1116\u001b[0m     wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[0;32m   1117\u001b[0m     dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m   1118\u001b[0m     _internal\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1120\u001b[0m \u001b[39mif\u001b[39;00m typed_storage\u001b[39m.\u001b[39m_data_ptr() \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1121\u001b[0m     loaded_storages[key] \u001b[39m=\u001b[39m typed_storage\n",
      "File \u001b[1;32mc:\\Users\\SameerAhamed\\anaconda3\\envs\\not_base_v2\\Lib\\site-packages\\torch\\serialization.py:217\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 217\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[0;32m    218\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    219\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\SameerAhamed\\anaconda3\\envs\\not_base_v2\\Lib\\site-packages\\torch\\serialization.py:182\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[0;32m    181\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 182\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[0;32m    183\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    184\u001b[0m             \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice(device):\n",
      "File \u001b[1;32mc:\\Users\\SameerAhamed\\anaconda3\\envs\\not_base_v2\\Lib\\site-packages\\torch\\serialization.py:166\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[1;34m(location)\u001b[0m\n\u001b[0;32m    163\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    165\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[1;32m--> 166\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    167\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    168\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    169\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    170\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    171\u001b[0m device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[0;32m    172\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "# Load the model and\n",
    "# Adjust the classifier head\n",
    "from torch import nn\n",
    "from going_modular.utils import load_model\n",
    "from pathlib import Path\n",
    "\n",
    "model_loaded = torchvision.models.efficientnet_b0().to(device)\n",
    "\n",
    "model_loaded.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, out_features=2)).to(device) # Hardcoded the class names\n",
    "\n",
    "model_loaded = load_model(model_loaded, Path(r\"model\\EfficientNet_b0-Wildfire_Classifier.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Validation Dataset\n",
    "\n",
    "valid_dataset = torchvision.datasets.ImageFolder(root=valid_dir,\n",
    "                                                 transform=automatic_transforms,\n",
    "                                                 is_valid_file=data_setup.check_Image)\n",
    "\n",
    "valid_dataloader = torch.utils.data.DataLoader(\n",
    "      valid_dataset,\n",
    "      batch_size=batch_size,\n",
    "      shuffle=False,\n",
    "      pin_memory=True,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [00:36<00:00,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss- 0.037713117969088224\n",
      "Validation Acc - 0.9874682741116751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the validation dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "model_loaded.eval()\n",
    "\n",
    "valid_loss = 0\n",
    "valid_acc = 0\n",
    "\n",
    "for X, y in tqdm(valid_dataloader):\n",
    "    # Copy to device\n",
    "    X , y = X.to(device), y.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    y_logits = model_loaded(X)\n",
    "\n",
    "    # 2. Calculate and accumulate loss\n",
    "    loss = loss_fn(y_logits, y)\n",
    "    valid_loss += loss.item()\n",
    "\n",
    "    # Calculate and accumulate accuracy\n",
    "    test_pred_labels = y_logits.argmax(dim=1)\n",
    "    valid_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "\n",
    "# Adjust metrics to get average loss and accuracy per batch \n",
    "valid_loss = valid_loss / len(valid_dataloader)\n",
    "valid_acc = valid_acc / len(valid_dataloader)\n",
    "\n",
    "print(f'Validation Loss- {valid_loss}')\n",
    "print(f'Validation Acc - {valid_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "not_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
